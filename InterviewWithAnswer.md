# Interview

[TOC]

## project

### ocr

### radar

### media

## components

### mysql

1. `DISTINCT`和`GROUP BY`有什么区别？

   `DISITINCT`是用来对目标字段去重的；`GROUP BY`是用来分组的，一般会接聚合函数。

2. `INSETR`和`REPLACE`有什么区别？

   `INSERT`是直接插入，遇到有UK的重复字段时会直报错；`REPLACE`遇到有UK的重复字段时会先删后插，其他情况与`INSERT`一样；

3. `DELETE`、`DROP`、`TRUNCATE`有什么区别？

   `DELETE`是DML操作，删除时需要记redolog，比较慢。只删除数据，不删除表结构

   `TRUNCATE`是DDL操作，只删除数据，不删表结构；

   `DROP`是DDL操作直接删表数据和表结构

4. `INNER JOIN`和`LEFT JOIN`有什么区别？

   - `INNER JOIN`的结果相当于两张表的交集，优化器会用数据量小的表作为驱动表，数据量大的作为被驱动表
   - `LEFT JOIN`的结果相当于左表+两张表的交集。优化器会用左表作为驱动表，右表作为被驱动表

5. 用过哪些Mysql函数？

   字符串相关；日期相关的；聚合相关的。这块需要注意的是：**不能在索引上使用函数，否则查询不会走索引**

6. LIKE语句中的%和_有什么区别？

   %表示0-n个字符；_仅表示一个字符

7. BLOB和TEXT有什么区别？

   范围都是1-65536。BLOB存储二进制数据，TEXT存储文本数据

8. 外键是什么？什么时候需要用？

   用外键约束将上下两张表联系起来，主要是为了维护两张表关系的一致性。`pipelines`和`models`这两张表就需要使用外键关联起来，并需要在models表中声明：如何应对pipeline的UPDATE & DELETE

9. 讲讲一条SQL语句的执行过程

   统一的流程是：连接器 -> 分析器（词法、语法分析，决定做什么）-> 优化器（选索引、联表、排序等，决定怎么做） -> 执行器（调用存储引擎接口）

   - Create、Update
     - 唯一索引，修改数据页（没有就去读，需要判断唯一性）、写redo log
     - 非唯一索引：写change buffer、写redo log。
   - Delete：写change buffer、写redo log。
   - Retrieve：通用流程

10. 删除操作会减少数据库文件的大小吗？怎么减小数据库文件的大小？

    不会，删除操作仅将数据行标记为删除状态；需要使用`ALTER TABLE t ENGINE=InnoDB;`重建表

11. Mysql长连接会有什么问题？怎么解决？

    长连接中使用的内存只有在连接释放时才会清理，容易造成内存占用过高，导致crash；定期执行**mysql_reset_connection**清理

12. 查询缓存是什么？有什么使用场景？

    优化查询速度的一个组件，适用于没有修改的静态表。当某张表出现修改时，Mysql会删除这张表所有的查询缓存

13. 讲讲Mysql优化器的作用

    选索引、联表、排序等操作

14. Mysql是怎么选择索引的？

    从扫描行数、语句执行代价（主要考虑非主键索引的回表）这两个角度进行考虑

15. Mysql是怎么确认扫描行数的？

    用随机采样的方式统计行数。具体来说就是从InnoDB中随机获取这张表相关的几个页面，统计页面中Item数量的平均值 * 页面数量，就能大概算出扫描行数

16. 哪些情况会导致索引失效？怎么解决？

    - 索引有多个列。需要从左到右，不跳中间列
    - 在索引列上用函数
    - 使用`!=`,`%string`,`<>`这样的操作会导致索引失效

17. 讲讲联表的过程

    选出驱动表和被驱动表。然后，将驱动表放在Join Buffer中，如果一次放不下，那就分成n段放。如果被驱动表的连接字段上有索引，那就根据索引进行条件过滤；如果被驱动表没有索引，那就在被驱动表上进行全表扫描。

    相应的调优手段是：在被驱动表的连接字段上加索引；增加join buffer size，减少扫描次数

18. 讲讲排序。有什么调优思路？

    有两个关键的变量：

    - sort buffer size：决定使用内存排序还是临时文件排序
    - row size：决定使用全字段排序还是RowID排序

    优化思路就是根据需求调大sort buffer size或者row size，防止出现文件排序或者回表

19. Mysql的缓冲池是怎么防止热点数据被淘汰的？

    将LRU链表分为yuang和old两部分（5:3）；新来的数据加入old list，当下次访问到的时候，发现已经在old list中超过1000ms，就提升到yuang部分

20. MyISAM和InnoDB有什么区别？

    InnoDB支持行锁；InnoDB支持MVCC；InnoDB支持事务；InnoDB支持外键

21. MyISAM和InnoDB执行`select count(*)`谁更快？

    MyISAM内部有存储count数量

22. InnoDB的事务是如何实现的？

    A：通过Undo Log做原子性。当执行rollback时，Undo Log会进行回滚

    C：通过原子性、隔离型、持久性来保证一致性状态

    I：MVCC和Next-Key Lock保证可重复读、读已提交级别的隔离性

    D：通过Redo Log做持久性

23. InnoDB有哪些特点？

    - change buffer：主要用于非主键索引，优化了随机读
    - double write：从存储引擎的角度看，将一组脏页刷新的磁盘时，如果刷到一半突然断电了，那就gg了。double write就是为了应对这样的场景。主要就是说，先将这一组脏页聚合起来，顺序写入到磁盘的某一个位置（2MB），之后再用随机写去刷新，刷新过程中即使出现了问题，也可以用顺序写入的部分进行恢复。
    - 自适应哈希索引：当InnoDB发现某个页面被频繁访问时，就会建立hash索引，加速访问速度
    - 预读机制：1Page=16KB；1Extent=64Page。当从这个Extent中读取的Page数量超过阈值时，就会去预读下一个Extent的数据

24. Change Buffer是什么？有什么作用？适用于什么场景？

    主要用于非主键索引的插入与更新、主键索引的删除操作。减少了随机读取数据页。

    适用于写多读少的场景；不适用于写后立刻读的场景

25. Change Buffer Merge的触发时机有哪些？触发时会做什么事情？

    读取数据页时触发；后台线程定期触发；关闭数据库时触发

    就修改合并至数据页中，然后由脏页刷新将数据刷回磁盘

26. 什么时候会执行脏页刷新？脏页刷新时，会修改redo log吗？

    内存中的脏页比例超过某个阈值；redo log写满了，需要往前推进时；系统内存不足时；系统空闲时；系统关闭时；

    脏页刷新时，不会修改redo log

27. 主键索引和非主键索引有什么区别？

    主键索引叶子节点放的是数据；非主键索引叶子节点放的是主键ID

28. Mysql为什么选择B+树做索引？B树和B+树有什么区别？

    Mysql的数据是放在磁盘中的，对于机械硬盘来说，读取的开销比较高（寻道、寻址）。为了减少读取次数，需要在一个节点上存放更多的数据。其次是，如果一个节点上放的数据比较多，那这颗树的层高就比较低，减少了遍历一颗树时的开销。

    B+树不在非叶子节点存数据，进一步降低层高；B+树使用链表连接叶子节点，增加对范围查询的支持速度；

29. 讲讲对联合索引的理解

    多列索引，按照从左到右的顺序进行排序。使用时，切记不要跳过中间的某个字段，否则可能导致索引失效

30. 讲讲对Mysql事务的理解？

    A（原子性）、C（一致性）、I（隔离型）、D（持久性）

31. 怎么理解事务的隔离级别？每个隔离级别会存在什么样的问题？

    隔离级别：

    - 读未提交：脏读、不可重复读、幻读
    - 读已提交：不可重复读、幻读
    - 可重复读：幻读
    - 串型化：事务排队，最直接没啥问题

    问题：

    - 脏读：读到其他事务没有提交的修改
    - 不可重复读：在事务中前后两次读一个值，读到的数据不一致
    - 幻读：在事务中前后两次读一个区间，读到的数据不一致

32. Mysql一致性是什么意思？一致性读呢？

    从某个一致性的状态转化到另外一个一致性的状态。就好比：A、B账户各有500块，不管他俩怎么转账，总数始终等于1000

33. Mysql是怎么实现读已提交和可重复读隔离级别的？MVCC是怎么实现的？

    使用MVCC（多版本数据控制）；

    视图：记录2个值（当前已提交事务的最大值、自己的事务ID）、1个数组（已提交事务最大值和自己的事务ID之间的数据，表示未提交的事务）。

    读已提交时在SQL语句执行时，创建这个视图；可重复读是在事务开始时，创建这个视图，并且在事务执行期间统一用这个视图。读取数据时，只能读到已提交事务的值。

34. Mysql是怎么解决幻读的？

    并发读用MVCC解决；当前读用Next-Key Lock（行锁+间隙锁）解决

35. Mysql有哪些锁类型？分别有什么用？

    MDL锁、行锁、间隙锁、Next-Key Lock

36. 如果在某行上加锁，什么时候提交？

    事务结束时提交

37. Mysql死锁是什么？

    两个事务互相等待对方先释放某一行的锁；主要有两种方式：

    - 等待对方持有的锁超时；
    - 主动发起死锁检测，即扫描事务列表，查询是否有某个事务持有行A的锁，并在等待行B的锁。如果有的话，就进行回滚

38. 怎么用Mysql实现悲观锁和乐观锁？

    乐观锁是说乐观的认为没有其他线程和我争抢锁，即读不加锁，更新再加锁；悲观锁是说悲观的认为有很多线程在和我争抢锁，读、更新都加锁

    - 乐观锁：使用数据版本进行控制
    - 悲观锁：for update，先下手为强

39. BinLog、Undo Log、Redo Log分别是什么？详细讲讲

    - binlog：Mysql提供的日志，记录原始的写入型SQL语句
    - redo log：InnoDB提供的日志，记录运行期间InnoDB的修改，主要是为了保证crash safe
    - undo log：主要用于实现MVCC和数据回滚

40. BinLog有哪些格式？有什么使用建议？

    statement（记录SQL原文，有可能导致数据不一致）；row（记录针对CRUD的操作，记录的日志可能比较多）；mixed

41. Undo Log是针对库还是针对表的？

    Undo Log存放在全局表空间中

42. 可以只使用BinLog吗？

    不行。BinLog没有Crash Safe的保证，没有记录数据页中完整的修改。

43. 可以只使用RedoLog吗？

    理论上可以，但常用BinLog来进行完整的备份与主从同步。

44. 为什么需要两阶段提交？

    主要是为了保证BinLog和RedoLog的一致性。如果没有的话：

    - BinLog->RedoLog：多出一个事务
    - RedoLog->BinLog：丢一个事务

45. 如何安全的修改表字段呢？

    修改表字段需要持有MDL锁，在事务中，为了防止表字段和返回结果不一致，会加一个MDL读锁。在修改字段时，TPS肯定会归0。在业务低峰期进行较好。

46. 怎么安全的复制表？

    ```mysql
    INSERT INTO t1(a, b, c) SELECT a, b, c FROM t;
    ```

47. 怎么安全的备份库？

    在可重复读的隔离级别下开启一个事务，在这个事务中备份数据。`mysqldump -single-transaction`

48. CPU的利用率很高，但是每秒处理的事务量太少。有什么解决思路？

    可能是出现了死锁，CPU忙于做死锁检测。用分布式锁控制访问Mysql的并发度

49. 长事务有什么影响呢？

    造成Undo Log中的回滚段过大；造成连接占用的内存过多

50. 如果数据库的命中率骤降并且更新语句执行的非常慢，有什么解决思路？

    判断是否引入了唯一索引，导致更新操作不能用change buffer。修改为正常的索引

51. Update、Insert、Delete时，RedoLog和Change Buffer分别有什么作用？

    Redo Log避免了随机写；Change Buffer避免了随机读

52. 怎么排查Mysql慢查询？

    在运行时，合理设置慢查询日志。通过慢查询日志定位带慢语句，之后在通过explain确认语句选用的索引是否正确

53. 怎么排查Mysql阻塞？

    看下是否有其他人用于占用了MDL写锁；看下是否有其他人占用了Next-Key Lock；

54. Select语句是否启用了事务？

    启用

55. 如何处理QPS暴增？

    加缓存，降低数据库的负载

56. 若Mysql IO出现瓶颈，怎么进行调优？

    写磁盘的就3个地方：Redo Log、BinLog、脏页刷新。BinLog不是很重要，可以尝试修改下BinLog的写入策略。

57. 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？

    BinLog中记录的是一个完整的事务，不能被打断；而Redo Log没有这个需求

58. 事务执行期间，还没到提交阶段，如果发生Crash的话，redo log肯定丢了，这会不会导致主备不一致呢？

    不会，BinLog只有在Commit之后才会发送给备库

59. 如何处理误删数据？

    一般在事前会给账户分配权限，还会做一些删除操作的特殊设置；BinLog启用Row模式，回滚数据

60. 主键ID为什么是自增的？

    尽可能的让B+树顺序插入，避免页分裂，让索引更加紧凑

61. 自增主键ID为什么是不连续的？

    插入失败时，事务回滚，但是主键ID不回滚，就会导致主键ID不连续。

62. 自增ID用完了怎么办？

    用完前分库分表；使用Alter Table修改主键类型为BigInt

63. 当自增ID到达上限是，继续插入会怎么样呢？

    到达上限之后，获取的主键都是一样的。插入会因为主键ID重复而报错

64. Mysql的主从复制原理

    主：将事务放进BinLog Cache中

    从：主动从主节点上拉BinLog，并进行处理

65. 怎么让Mysql支持表情？

    使用utf8_mb4字符集

66. Mysql的行锁是怎么实现的？

    通过在主键索引上加锁完成的

67. 什么是事务？

    并发控制的基本单位，要么全部成功，要么全部不成功。具有ACID属性

68. 为什么要拆分大的DELETE操作？

    长时间占用MDL读锁；长事务导致连接占用的内存过多；DELETE会造成Undo Log过大；容易造成锁冲突，阻塞其他事务

69. char和varchar有什么区别？

    char(20)固定长度，范围1-255，申请多少就用多少，多出的部分用空格代替；varchar可变长度，范围1-255，申请的是可变长度，实际长度的len+1

70. 锁有什么优化思路？

    有冲突的行往后放，减少锁的粒度；尽量使用相同的加锁顺序，防止死锁

### redis

1. redis缓存满了怎么办？

   redis在配置文件中提供了几种策略，大致为：LRU，random，return error。可以根据需求进行配置

2. redis为什么这么快？

   纯内存操作；网络IO模型（epoll-ET）；线程模型（单线程+命令排队+无锁）；高效的数据结构

3. 讲讲redis的基础数据结构及底层结构

   - 基础：
     - string；
     - list(quick-list)；
     - hash(zippiest、hashtable)；
     - set(ziplist、hashtable)；
     - zset(ziplist、skiplist)；
   - 拓展：bitmap、cell、bloomfilter

4. 为什么zset使用跳表不使用二叉树？

   skiplist，需要支持范围查询。Hash是无序的，不能用；红黑树不支持范围查询，不能用

5. ziplist怎么查找某个key？zset如果是ziplist，怎么查找某个key？

   ziplist大致是这样一个结构：header + item length + items + footer。在ziplist中查找数据，用的是遍历的方式

6. 什么时候需要用bloom filter？讲讲bloom filter原理？有什么缺点？怎么解决这个缺点？

   - 应用场景：图片md5去重：如果不存在，那就进行处理；如果存在，那就去mongodb中进一步检查是否真的存在。有效降低直接查询mongo的次数；leveldb中好像有用
   - 特征：如果bf告诉你不存在，那就肯定不存在；如果bf告诉你存在，那只是可能存在

   - 原理：首先一组初始化为0的buckets，用一组hash计算key，计算完成后插入buckets中。查询时，也是先计算，然后看对应的buckets中是否有值。如果没有值，肯定不存在；如果有值，不一定存在
   - 缺点：bf不支持删除操作
   - 解决方式：使用cuckoo filter（布谷鸟过滤器）

7. cell是什么？什么时候会用？和nginx的限流相比有什么区别？

   - 漏桶限流组件；

   - 分布式限流；
   - 区别：nginx只能用于单个nginx示例，不适用于多层负载均衡中的限流场景。都是漏桶限流，好像没什么区别

8. 讲讲hash扩容的过程

   当len(buckets) = len(items)时，会发生渐进式rehash。即在old hashtable上发生curd操作时，会将old->new

9. redis是怎么删除数据的？有哪些删除数据的命令？不同的删除命令有什么区别？

   - 后台线程定时删除+访问时惰性删除
   - delete（同步阻塞删除）
   - unlink（异步非阻塞删除，真正的删除操作在后台线程中执行）

10. 为什么需要持久化机制？

    从原理上说，他解决的是高可用问题，防止数据丢失；但实际使用上，主要是为了解决冷启动

11. 讲讲aof和rdb。有什么区别？使用场景有哪些？

    - rdb：使用二进制的方式保存当前进程内存快照。解决冷启动问题；
    - aof：每次执行写入命令时，先写内存，再写aof文件。解决实时命令持久化问题
    
12. 讲讲aof rewrite

    当AOF文件过大时（有配置项），会用当前的内存快照重写aof文件。在重写的过程中，通过Fork产生子进程，重写过程会用到COW

13. 如何选择合适的持久化方式？

    - 如果能接受小时级别的数据丢失，选择RDB
    - 如果不能丢数据，选择AOF

14. 如果要同时更新多个key，怎么保证原子性？lua script在redis中有什么问题？

    内嵌lua脚本；要注意lua脚本的超时时间，默认5s；

15. 两个线程同时写一个key会怎么样？怎么保证顺序性？

    根据请求到达顺序进行排队处理；用分布式锁或者watch..mutil..exec这样打包一组命令

16. sentinel和cluster分别解决了什么问题？

    sentinel解决高可用问题；cluster解决了单实例写入问题

17. 讲讲redis sentinel、redis cluster的选举过程

    - sentinel：主观下线->客观下线->sentinel领导者选举(raft)->选择新的主节点->让其他从节点同步主节点
    - cluster：主观下线->客观下线->持有slots的节点投票选举新的主节点->其他从节点同步新的主节点

18. 主从副本的数据同步方式？

    全同步用rdb；半同步用aof

19. redis cluster是怎么做数据分布的？为什么选用slots？如果用一致性哈希有什么问题？

    用槽( 0~16383)的方式分布数据，slot = hash(key) / 16384

    一致性哈希：存在一个指定长度的hash环，然后通过hash(key)，将数据映射到环中的某一个节点上。这样做的优点是：增加或者删除节点时，仅影响相邻节点的数据；缺点是，数据分布不均匀，容易造成数据倾斜。

    slots就相当于固定长度的一致性哈希+虚拟节点。

20. 讲讲redis、mysql数据同步策略

    - 先删缓存，再写数据库：线程A删了cache -> 线程B cache miss & 从db中获取就数据放到缓存中 -> 线程A update db。走完上述流程后，cache中依旧是old data。这种方案不可行
    - 先写数据库，再删缓存：线程A更新DB -> 线程B从cache中获取了old data -> 线程A删除cache -> 线程C触发miss，更新cache中的数据。这种方案是可行的
    - 只更新数据库，然后通过binlog将数据自动同步到缓存中。最终一致性策略

21. 有人说Redis只适合做缓存，不适合做数据库，你怎么看？

    不适合做数据库：缺少事务支持；占用大量内存

22. 讲讲缓存穿透、缓存击穿、缓存雪崩。有什么好的处理建议？

    - 缓存穿透：数据库没有数据，缓存也没有数据。解决方式：布隆过滤器拦截；缓存空对象；使用分布式锁限制同时访问存储端的并发量
    - 缓存击穿：数据库有数据，缓存没有数据。解决方式：定期更新热点Key TTL；使用分布式锁限制同时访问存储端的并发量
    - 缓存雪崩：大量Key同时失效。解决方式：Key的过期时间+Random Number；使用分布式锁限制同时访问存储端的并发量

23. 讲讲用redis做分布式锁需要注意哪些事项？

    加锁要有`create if not exists`语义，并且为了防止锁超时，需要设置random key；解锁要有`del if equal`语义

    redlock是多实例分布式锁方案，并且实例要无关。在超过n/2+1的节点上`set nx ex`成功即加锁成功。 

24. 怎么发现redis大key？大Key可能引发哪些问题？有哪些处理建议？

    - 排查：`redis-cli --bigkeys`、`debug object key`

    - 问题：针对大key的curd操作可能变慢，阻塞应用
    - 处理建议：对大key进行拆分

25. 怎么发现redis的热点key？热点Key可能引发哪些问题？有哪些处理建议？

    - 排查：`redis-cli --hotkeys`

    - 问题：从集群的角度看，容易造成流量倾斜；热点Key超时将导致缓存击穿，影响DB的稳定性
    - 处理建议：增加热点key的过期时间防止缓存击穿；使用分级缓存，应用程序统计访问同一个cache的次数

26. 怎么排查redis的慢操作？怎么处理？

    - 排查：`slowlog get`
    - 处理思路：
      - 是否使用了复杂度高的命令，例如keys、hgetall等
      - 是否操作了bigkey，使用：`redis-cli -a xxxx -d 0 --bigkeys`检测
      - 查看cpu利用率，判断是否到达了实例处理上限
      - 查看IO，判断是否出现了写rdb或者aof rewrite

27. 主从部署+读写分离，可能遇到哪些问题？怎么解决？

    半同步采用AOF机制，存在些许延迟。导致可能读到已经删除或者已经过期的数据，这个需要应用容忍这种情况。

28. 在redis的使用上有什么建议？

    - 不要在master上做RDB或者AOF，将备份工作交给从节点
    - 使用链式部署结构，降低节点压力

29. redis事务有什么问题吗？

    不建议使用。redis只是一组批量语句提交，若其中一行执行失败，依旧会顺序往下执行。如果一定要用，建议使用lua script，至少可以在逻辑中加入一些rollback

### kafka

1. 为什么要使用kafka？

   异步处理；服务解耦合；请求削峰；提升吞吐量

2. kafka有哪些缺点？

   部署需要引入zk，有点麻烦；不支持延时消息；不支持多分区消息有序

3. kafka有哪些特点？

   高吞吐（顺序读写文件、消息索引）；高拓展（topic partition、consumer group）；高可靠（通过写磁盘进行持久化、分区副本）

4. kafka如何实现高吞吐？

   顺序读写文件；消息索引（在.index文件中存储.log文件的msg offset<->log file position，并将.index文件映射到内存中）；同步消息时采用零拷贝技术

5. kafka的高可靠是怎么实现的？

   两个角度：消息会被顺序持久化至磁盘；采用分区副本（主分区读写，从分区只负责同步），使用acks参数控制写入动作

6. kafka的高拓展是怎么实现的？

   两个角度：consumer group提升消费能力；多partition提升写入能力

7. 讲讲kafka的体系结构

   Broker；Producer；Consumer Group、Consumer；Topic、Partition；

8. kafka分区的目的？

   横向拓展消费能力；采用分区副本保证消息的高可靠

9. 如何保证kafka消息有序？

   单一partation

10. 讲讲kafka的消息一致性。

    从HW和LEO的机制交付来回答。

    - HW（High Water Mark）：ISR（In-Sync Replication）中，Offset最小的位置，相当于木桶的最短板。只有HW以上的消息才能被读取，控制消费者读取数据的位置。
    - LEO（Log End Offset）：ISR中，Offset最大的位置，相当于木桶的最长板，即主副本Offset。

11. 怎么做kafka消息幂等？

    MongoDB中我用了唯一索引，ES不清楚；Mysql可以使用唯一索引；

12. kafka在什么情况下会丢消息？

    acks=0时；producer recv&commit，还没来得及处理，就crash了；

13. kafka在什么情况下会出现消息重复？

    producer采用auto commit，消费了但没有commit，然后出现了crash

14. consumer和consumer group是什么关系？

    consumer属于consumer group，从一个或者多个topic中读消息；每个consumer至少能分到1个partition

15. 讲讲consumer group rebalance

    消费者数量或者分区数量发生变化时，controller将分区重新分配给某个consumer的过程

16. 讲讲partition rebalance。

    broker的数量发生变化时，为了保证每个broker的吞吐大致平衡，需要手动调整下partition在broker list中分不

17. kafka分区数量可以减少吗？

    不行，对于减少的分区中的数据如何处理比较复杂

18. 讲讲kafka的分区副本

    主副本负责读写，从副本负责同步数据。引入一些ISR、OSR，HW、LEO这样的概念。需要注意的是，分区副本的数量（包含主副本）不能超过broker

19. zk在kafka中有什么作用？

    维护kafka节点状态，包括但不限于：controller选举、broker管理、配置管理等

20. consumer长时间没有pull，会有什么问题吗？

    pull中存在心跳，长时间没有心跳，会导致被踢出consumer group，触发rebalance

21. 如何减少数据丢失？

    acks=all；在producer中，处理完消息之后，再commit；加入幂等性处理重复的消息；禁止OSR中的副本竞选主副本

22. offset有什么作用？

    kafka中的消息是不能修改的，使用offset能描述唯一的消息位置；使用offset和index文件建立索引，加速读取

23. 如何修改kafka能接受的最大的消息大小？

    同时修改producer、broker、consumer中的配置项

24. 如何估算kafka集群的大小？

    使用Kafka-consumer/producer-pref-test.sh这样的工具，结合消息大小测试下

25. 如何调优kafka？

    根据吞吐、延迟等需求，从broker、topic、consumer、produce以及JVMr这5个角度分开去看

26. kafka为什么不支持读写分离？

    避免发生一致性问题

27. kafka磁盘容量规划需要考虑哪些因素？

    消息大小、留存时间、是否压缩

### mongodb

1. 什么是mongodb？

   文档型数据库。高性能（C++出品）、高可靠（副本集、数据落盘）、高拓展（cluster）

2. 什么是聚合操作？需要注意哪些事项？

   mongo聚合是一个分组再统计的过程，常用aggregate函数。分为以下步骤：match -> project -> group -> sort -> skip -> limit。如果数据量较大，需要打开AllowUseDisk选项，防止出现内存问题

3. mongodb相比于mysql有哪些优势？

   - 没有schema，数据格式灵活，变更方便
   - 高可靠，高拓展
   - 查询能力丰富，聚合很好用

4. 副本集是什么？

   为了保证高可用，引入了副本集。有几个需要注意的地方：

   - mongo的副本集没有哨兵
   - 可以用来做读写分离，但是需要业务层容忍同步延迟数据
   - 当一个副本发现无法ping通另外一个副本时，整个集群会采用raft选举出新的主节点
   - 在部署上建议使用一主一备一仲裁者

5. 使用副本集时，怎么尽可能保证数据都写入成功？

   这一点和kafka比较像。有两个需要注意的地方：

   - 写入的副本数量，可选0，1，n。类似kafka acks
   - 落盘操作。0表示仅write，1表示write+fsync

6. mongodb有哪些索引？

   普通索引；复合索引；唯一索引；TTL索引。使用方式：db.ensureIndex(...)这样子

7. mongodb索引的实现原理？

   b-树。相比于Mysql有两个区别：

   - 所有节点都存放数据。查询效率不稳定，在log1~log2n区间内
   - 叶子节点没有链表相连接。对范围查询支持的不好，适合单点查询

8. mongo怎么保证crash-safe？

   顺序写journal日志保证，类似于redolog

9. mongodb在更新、删除、插入时，是立刻写入文件吗？

   不是。写journal日志，改内存之后，直接返回。由后续的脏页刷新流程将脏页写回文件。

10. 为什么mongo的存储文件比预估的稍大些？

    mongo会为每一个文档预留一些padding，防止文档增长时因为空间不足导致位置发生变化

11. 主从副本之间怎么同步数据？

    全量同步；oplog（固定集合）半同步

12. 分片是什么？

    为了拓展写入能力，引入了分片。有几个需要注意的地方：

    - 使用前需要声明片键，为了保证数据分布尽量均匀些，最好使用随机片键。
    - 数据写入的基本单位是chunk（64MB），chunk维护了一个片键范围，例如1-100。当chunk足够大时，会发生分裂，从而产生新的片键
    - 部署中存在3个重要的组件：config、router、cluster

13. 如果一个分片正处在迁移期间，在这个分片上出现更新会发生什么事情呢？

    在迁移期间，所有的请求都会被导入old chunk。只有在迁移完成之后，才会更新router中的metadata

14. mongo有事务吗？怎么理解多文档事务？

    - 单文档事务：用文档锁和journal来保证文档、索引及oplog的更新是一致的

    - 多文档事务：这块没用过（Snpashot隔离级别）

15. 如果一个分片意外终止时，发起一个查询会发生什么事情？

    如果有设置`Partial`选项，会返回查询结果；如果没有设置，会返回查询错误

16. 怎么排查mongo的慢查询？

    在业务层通过监控发现慢查询，然后用explain进行判断。基本上都是没有用索引

17. mongodb的数据模式与mysql有什么区别？

    - 不需要预先声明schema，很灵活
    - 尽量做成嵌套式声明

18. 怎么安全的备份数据？

    用mongo提供的工具进行备份；或者对db加锁，然后再备份数据

### nginx

1. Nginx有那些特点？

   - 快
   - 高拓展性。采用模块化设计，有庞大的第三方模块可供选择
   - 高可靠性
   - 低内存消耗
   - 高并发
   - 热部署。采用master-worker进程分离，在不间断服务的前提下，就可以做到更新配置项

2. 为什么Nginx Master和Nginx Worker都可以监听80端口呢？

   - Master监听80端口
   - 从Master Fork出n个Worker，Worker继承了Master的Socket资源

   根据以上步骤，就出现了Worker、Master共享80端口的情况。如果此时有请求到达，所有的Worker都会被唤醒，但仅有一个Worker可以成功调用`accept()`获取到链接。之后，这个获取到链接的Worker就可以正常的处理请求了。

3. 主要用Nginx做什么？

   负载均衡；反向代理

4. Nginx有哪些负载均衡算法？

   轮询；hash ip

5. 有哪些常用的Nginx Module？

   Core、Limit Request、Limit Conn、Proxy、Upstream这几个

### kfp

全称kubeflow pipeline，是一个基于k8s的任务调度框架。提供了以下几个重要的概念：

- pipeline：流程模板
- experiment：一组训练任务的统称
- run：从流程模板实例化出来的一个实例，一次训练任务。
- step：训练任务中的一个步骤
- artifacts：step之间的input/ouptut文件。存放在minio中
- parameters：step之间有两种参数传递方式：一种是parameters字符串；一种是artifacts文件

从使用上来看，kfp有以下几个重要的点：

- kubeflow pipeline提供了一组rpc接口。可以直接在业务层进行调用
- kubeflow pipeline提供了一个python sdk，用来定义pipeline。写出来并compile之后，直接上传到kfp上就行

在kfp1.7.1之后，社区提出了一个Pipeline IR（Intermediate representation）的计划。是为了解决这个问题：之前的python sdk生成的是一个yaml文件，但是这个文件仅能在k8s algo调度器上执行。为了解耦调度器，所以提出了Pipeline IR。就是用Python Compile出一种中间描述文件，再由kfp backend对这个文件进行解释以适配不同的调度器

### docker

微服务；容器化；资源隔离；主要用到

- Namespace：资源隔离
- Cgroups：资源限制

### k8s

容器调度平台，常用以下组件：pod、cronjob、deployment、statefulset、configmaps、secrets等。ingress主要是替代service->pod的DNS方案，使用Nginx将外部流量导入到内部。这块仅仅是使用，没有深入研究原理与实现。

1. 用过哪些service？
   - NodePort
   - ClusterIP：通过iptables转发
   - Headless Service：将负载均衡暴露给外部服务去做。例如grpc
   - Ingress Service：将集群外部的流量导入到集群内部

## os

1. 什么是操作系统？讲讲操作系统的体系结构

   管理硬件与软件的应用程序，是一切App的基石。

   分为用户态和内核态。内核运行在内核中，有以下几个重要的模块：系统调用模块、文件管理、进程管理、内存管理、网络管理、设备管理

2. 用过哪些Linux工具

   C++、文件系统、网络、内存、进程以及其他一些小工具

3. Linux上的App能否在Windows上运行？

   不行。Linux的App是ELF格式；Windows的App是PE格式

4. 应用态和内核态是如何切换的？

   进入系统调用时，系统调用会被转成一个Num。然后将这个Num放在固定的寄存器中，执行`syscall`指令，即可进入内核态。IA32体系下，是通过软中断进入内核态的。

5. 进程、线程、协程有什么区别？

   进程是资源管理的基本单位；线程是调度的基本单位；协程完全由用户态管理，并且在拥有自己的调用栈，切换时无须陷入内核态，开销非常小

   进程切换时涉及到页表的切换，相比于线程慢很多。

6. 并发和并行有什么区别？

   并发是指一段时间内并发执行的任务数量；并行是指在一个时间点上并行运行的任务

7. 进程、线程切换有什么区别？

   进程：切换页表；切换内核栈

   线程：仅需要切换内核栈

8. 进程间通信方式有哪些？

   IPC的话有以下几种：管道、信号、共享内存+信号量、消息队列、Socket。微服务架构很少用，内部通信用Grpc，外部用Http

9. 线程的同步方式有哪些？

   互斥锁、信号量。写一段生产者、消费者的伪代码：

   ```c++
   mutex mutex;
   cond cond;
   queue<int> queue(10);
   
   void consumer() {
     while (1) {
     	mutex.lock();
     	while (queue.empty()) {
       	cond.wait();
     	}
     
     	task = queue.pop();
       mutex.unlock();
       
       cond.single();
       if (task == nil) {
         break;
       }
     	process(task);
     }
   }
   
   void producer() {
     for (int i=0; i<1000; i++) {
       mutex.lock();
       while (queue.full()) {
         cond.wait();
       }
       
       queue.push(i);
       mutex.unlock();
       
       cond.single();
     }
   }
   ```

10. 什么是死锁？死锁产生的条件有哪些？

    线程A持有资源A，在请求资源B；线程B持有资源B，在请求资源A

    修改开发模型，使用TaskQueue模式；发生时，使用gdb调试core dump文件即可

11. 讲讲Linux的进程调度策略

    Linux采用CFS（完全公平调度算法）调度进程。内核会统计每个进程在CPU上的运行时间，并在内核用红黑树进行排序。调度时，会选择红黑树中的左子节点，也就是运行时间最短的进程。有两种调度方式：

    - 当前进程陷入IO时，会主动让出CPU
    - 当前进程的运行时间过长，在进入系统调用或者中断时，会被抢占

12. 进程有哪些状态？

    创建；就绪；运行；阻塞；终止

13. 什么是分页？

    将进程虚拟内存空间和物理内存空间划分为大小固定的块，方便映射与管理。这块主要使用页表管理映射关系。

14. 什么是分段？

    分段是一个逻辑上概念。例如Linux的进程空间被划分为：代码段、数据段、BSS段、堆、栈等

15. 分页和分段有什么区别？

    页的大小不可变；段的大小是可变的

    分页主要用于操作系统管理内存空间；分段主要为了使程序在逻辑上被划分为不同的区间和类型

16. 什么是缓冲区溢出？有什么危害？

    程序向缓冲区中添加的数量超过缓冲区的容量。cpp一般会报Segment Fault的错误

17. 软链接和硬链接有什么区别？

    文件在FS层存储为一个Inode。硬链接是两个文件使用同一个Inode；软链接是有两个Inode，一个里面放文件数据，一个里面放路径

18. 孤儿进程、守护进程、僵尸进程分别是什么？

    孤儿：父进程先退出，子进程被托管给0号进程init

    僵尸：子进程退出后，会发出一个信号，父进程需要根据这个信号给子进程收尸。否则就会变成僵尸进程

    守护：运行在后台，随操作系统启动而启动，与其他进程没有什么关联

19. 什么是中断？

    中断分为软中断和硬件中断。收到中断时，操作系统会保存当前上下文，优先执行处理中断信号

20. 动态库和静态库有什么区别？

    静态库是一组.o文件的集合，会在链接时，将这些.o与目标文件打包成可执行二进制文件。

    动态库是elf格式的文件。在链接时，会在可执行中填充动态库中的函数符号地址；在运行期，加载动态库并解析符号

21. 有哪些常见的页面置换算法？

    结合最新的swap交换内存，有LRU、FIFO等几种

## network

### tcp/udp

1. TCP中的KeepAlive和HTTP的KeepAlive是同一个意思嘛？

   不是。http的主要用来做长短链接；tcp是保活探测的

2. CLOSE_WAIT和TIME_WAIT分别是什么？怎么解决？

   主动发起关闭的一方出现TIME_WAIT；被动响应关闭的一方出现CLOSE_WAIT

   - TIME_WAIT会在第4次挥手后出现，持续2MSL。主要是为了防止挥手发送的ACK丢失，对端再次发送FIN时无法响应。可以通过调整内核参数进行修改
   - CLOSE_WAIT出现在第2次、第3次挥手之间。Client主动发送FIN后，Server的数据可能还没有发送完成，并且为了方式FIN超时，就会先响应ACK。

3. 讲讲Ping的原理

   ping采用网络层的ICMP协议，测试两台主机的连通性。

4. TCP和UDP有什么区别？

   TCP是面向连接的、可靠的字节流协议

   UDP无连接、不可靠、使用数据报的协议

5. 详细讲讲TCP的三次挥手

   - SYN + Seq x
   - ACK + SYN + Seq y
   - ACK 

6. UDP如何实现可靠传输？

   引入seq+ACK；引入数据校验；引入流量控制；引入超时重传

7. DNS为什么用UDP？

   避免握手、挥手的开销；减少报文头部大小；

8. 为什么必须是3次？能不能是2次？能不能是4次？

     因为TCP是全双工的，需要双方都显式的告知对方自己的Seq信息。并且在建立连接时没有数据发送，所以可以将SYN+ACK一起发送

9. 详细讲讲TCP的四次挥手

   FIN -> ACK -> FIN -> ACK

   主动发起的一方状态变化如下：FIN_WAIT_1 -> FIN_WAIT_2 -> TIME_WAIT -> CLOSED

   被动响应的一方状态变换如下：CLOSE_WAIT -> LAST_ACK

10. 为什么需要4次挥手？

    全双工通道；第二次挥手为了防止FIN超时，会直接发送，不等待数据；处理完数据后，对端会主动发送FIN

11. 为什么需要2MSL的TIME_WAIT状态呢？

    主动Close在进行第4次挥手后，会进入TIME_WAIT状态，并等待2MSL。有两个作用：

    - 防止收到旧数据
    - 防止对端没有收到第四次挥手，从而再次发送FIN

12. 讲讲TCP的粘包和拆包

    因为TCP是面向字节流的传输协议，随意可能会导致应用层的Package粘在一起。有以下几种解决方式：

    - 定长
    - 像HTTP一样使用特殊的字符标示终止位置
    - 更加复杂的业务层Package设计

13. TCP有哪些特性？

    - 三次握手
    - 四次挥手

    - 流量控制

      在发送快、处理慢这种场景下，抑制发送端的发送速率。这块主要使用了一个滑动窗口来实现的，每次发送数据，都会从对端获取剩余窗口大小，然后根据这个窗口大小发送数据；如果窗口为0，发送端会启用一个定时器，定时探测对端窗口，知道窗口不为0

    - 拥塞控制：防止将太多的数据注入到网络中

      > 拥塞窗口（初始化=1）；慢启动门限（初始化=16）

      - 慢启动：每收到一个ACK，就将拥塞窗口+1。在每轮次中，拥塞窗口翻倍。是一个指数增长的过程
      - 拥塞避免：每收到一个ACK，就将拥塞窗口+1/cwnd。在每轮次中，拥塞窗口增加一个。是一个线性增长的过程

      在上述两个发送数据的阶段，可能会遇到以下两种情况：

      - ACK超时：意味着网络拥塞非常严重，连对端的ACK都收不到了。这个时候，sstresh = sstresh/2, cwnd=1。从慢启动重新开始
      - 收到3个重复的ACK（丢包时，就会一直发送已经接受的ACK）：意味着出现了偶现的丢包，网络拥塞不是很严重。那这个时候，sstresh = sstresh / 2，cwnd = sstresh，并且无须等待丢包的ACK超时，直接发送丢包，并且进入拥塞避免阶段。这个过程就叫快速重传、快速恢复

    - 超时重传

      发送数据时，会启用一个定时器。如果在定时器内没有收到ACK，就会重新发送数据

14. 什么是全连接队列？什么是半连接队列？

    半连接队列：SYN队列，默认128。满了之后会丢弃新的连接请求

    全链接队列：Accept队列，默认128。满了之后，会丢弃Client发送的ACK

15. TCP是如何确保可靠性的？

    在连接创建、终止阶段，使用3次握手，4次挥手保证；

    在数据传输阶段，使用应答-响应、seq number、数据校验、ack、超时重传的方式，保证数据被正确传输与组装

16. TCP_NODELAY有什么作用？

    当启用TCP_NODELAY时，即使你的数据包很小，也会直接发送；否则等超时（200ms）或者满足MSS（大小1460字节）后发送数据

17. tcp三次握手最后一次失败了会怎么样？此时客户端发数据过去服务端会怎么处理？

    发送SYN+ACK时，会启动一个定时器等待ACK。如果长时间没有收到ACK，就会重新SYN+ACK

18. 有了IP地址，为什么还需要MAC地址？

    IP就像家庭地址，作用于上3层；MAC是详细的收件人，作用于下2层

19. 讲讲IO多路复用

    IO模型中的一种：

    - select：1024固定长度的数组；每次都需要copy到内核中；内核顺序遍历，性能差
    - poll：与select基本一致，不是使用链表保存poll events，没有长度限制
    - epoll：使用时无需copy数据至内核；然后在内核中使用红黑树管理全部事件，使用链表管理已触发事件；并且是为每个管理的事件设置了回调，没有使用线性轮训的方式

20. 讲讲epoll LT模式与ET模式有什么区别？

    - LF：当数据没读干净时，LT会在下次轮询中通知你继续处理
    - ET：不管你数据有没有读干净，ET只有在触发Callback时，才会通知你

### http

1. 有哪些常用的http错误码？

   10X没用过；

   20X表示请求成功；200=OK；201=新创建了一个资源；

   30X表示重定向；302、307=临时重定向；301、308=永久重定向。301和302在某些实现上会被修改为get，常用307、308

   40X表示请求信息错误；400=请求参数错误；401=身份验证不通过；403=权限不对；404=没有找到资源；408=请求超时

   50X表示服务端错误；500=internal error；502=bad gateway

2. HTTP常用的请求有哪些？

   GET、POST、PUT/PATCH、DELETE

3. CDN是什么？

   Content Delivery Network。主要部署在靠近用户端的地方，用于缓存热点数据，防止大量请求回源。

4. URI和URL有什么区别？

   统一资源标示符、统一资源定位符，URL是URI的一个子集。

5. 正向代理和反向代理有什么区别？

   代表客户端向服务端发送请求；代表服务端响应客户端的请求

6. 讲讲ISO七层网络模型

   应用层：HTTP、DNS、FTP

   表示层：把数据转换为合适、可理解的语法和语义

   会话层：维护网络中的连接状态，即保持会话和同步

   传输层：TCP、UDP

   网络层：IP、ICMP

   数据链路层

   物理层

7. 从URL输入地址到显示主页的过程？

   DNS解析 -> TCP三次握手 -> 发送HTTP请求 ->获取请求结果 -> 渲染 -> 四次挥手 

8. 详细讲讲DNS域名解析流程

   浏览器缓存 -> 操作系统缓存 -> 操作系统hosts文件 -> DNS服务器

9. 如果访问某个页面很卡怎么办？

   DNS解析链路太长；请求的服务器负载过高；请求返回的资源多，渲染时间长

10. HTTP有什么特点？

    优点：无状态；可拓展；使用可靠的传输层协议

    缺点：明文传输不安全；缺乏身份认证；缺少数据完整性校验；性能问题（长链接的队头阻塞问题）

11. 讲讲HTTP不同版本之间的区别

    - 1.0：默认使用短链接，不过可以主动设置长链接
    - 1.1：默认使用长链接（keep-alive）；引入了分块传输文件的方式
    - 2.0：head+body采用二进制编码；引入了stream和frame的概念，解决了队头阻塞的问题；引入了自适应的头部压缩算法

12. POST和GET有哪些区别？

    GET是从服务器上获取资源；POST是让服务器对请求中携带的数据进行处理

    GET的请求参数是用&连接起来的；POST的请求方式比较多样：application/json，multipart/form-data等

13. 讲讲Http有几种文件传输的方式？

    Content-Length；Chunked分段传输。可以优化大文件下载体验

14. 返回文件时，怎么控制文件名称？

    ```go
    // 采用url编码，由前端负责转成utf-8
    //注意顺序！！
    w.Header().Set("Content-Disposition", "attachment; filename="+url.QueryEscape(zipFilePath))
    w.Header().Set("Content-Type", "application/x-zip-compressed")
    w.WriteHeader(statusCode)
    ```

15. 怎么实现分段上传与分段下载？

    分段上传：使用POST + multipart/form-data自行开发接口

    分段下载：使用Range Header进行请求，服务端使用Content-Range Header进行响应。然后在客户端自行组装

16. 如果HTTP使用短链接的话，是那一端主动Close链接的？长链接呢？

    不论长短链接，都是服务端主动Close的。

17. 主动Close会产生哪些问题？怎么处理？

    主动Close的一方会存在2MSL的TIME_WAIT状态。在这段时间内，端口无法被重用。为了方式TIME_WAIT过多，可以采用以下方式：

    - 使用长链接
    - 修改进程最多可以打开的FD数量。默认1024，需要修改为1048576
    - 修改内核中和time_wait相关的配置

18. 讲讲HTTPS的流程

    HTTPS主要从以下角度对HTTP进行了优化：

    - 加密传输：
      - 对称加密：加解密采用同样的密钥
      - 非对称加密：加解密采用不同的密钥
      - 混合加密：混合使用对称、非对称加密
    - 数据完整性校验：摘要
    - 身份认证：
      - 签名：对摘要使用私钥进行签名
      - 验签：用公钥解密，获取签名后。再使用加密套件中的摘要算法进行计算并比对的过程

    创建HTTPS的过程如下所示：

    - 客户端发起HTTPS请求

    - 服务端将证书发送给客户端

      > 证书就是一个打包的公钥，包括用途、日期、摘要等信息

    - 客户端对校验证书的合法性。

      > 走浏览器内置的CA认证链，判断公钥是否有效

    - 如果合法的话，就从证书中取出公钥。并生成一个用于对称加密的密钥，用公钥加密后，发送给服务端

    - 服务端收到加密的密钥后，用私钥解开，就能开始和浏览器用对称加密的方式传递数据了

    上述这个过程保证了加密传输，数据完整性和身份认证是使用以下机制完成的：

    - S->C、C->S时，都会用对称密钥计算摘要
      - S->C：服务端用私钥对摘要进行签名，客户端验签
      - C->S：客户端用公钥对摘要进行签名，服务端验签

19. 讲讲HTTP2有哪些特性

    Header压缩，不再使用明文的Header；使用二进制帧保存数据，大概分为：Header Frame、Data Frame、Control Frame这几种；使用Stream发送数据，多个流共用同一个链接；

20. HTTP和HTTPS的区别

    HTTPS = http + ssl/tsl。https从以下3个角度加强http：

    - 消息明文传输。采用对称加密+非对称加密
    - 缺少身份认证。数组签名与数字证书
    - 未校验数据完整性。采用摘要算法

21. 什么是数字签名？什么是数字证书？

    数字签名：对公钥进行签名用的是第三方机构的私钥。浏览器在获取证书后，需要用内置的CA链对公钥进行验签

    数字证书：一个打包的非对称公钥的，包括用途、日期、摘要、签名等。需要注意的是，

22. 讲讲Session、Cookie、Token分别是什么。分别由什么优缺点？

    维护请求状态的一种方式。

    - Session：将状态存放在服务端，Session就是用Cookie实现的，会在Response.Set-Cookie字段中加入SessionID。然后在服务端的KV上保存SessionID对应的详细信息。

    - Cookie：将状态存放在浏览器上。存在一些属性，例如HttpOnly，使用时需要详细设置。主要会用到Set-Cookie、Cookie Header
    - Token：将状态经存放在浏览器上，并在每次请求中都携带Token，验证通过后即可进行正常的访问。

### grpc

1. Grpc是什么？Grpc有哪些服务类型？

   跨语言的远程服务调用。简单RPC服务、双端流式服务、客户端流式服务、服务端流式服务

2. Grpc适用于什么场景？

   内网的服务间调用；跨语言调用

3. Protobuf在Grpc中有什么用？

   用于msg序列化，常用的复杂类型：map、repeat、union、enum、struct、timestamp等

4. 讲讲Grpc的实现原理

   Grpc是基于Http/2实现的。主要使用Frame、Stream的这两个属性。

   - Status、Errcode、Version等Metadata存放在Header Frame中
   - Req & Rsp Data等Metadata存放在Data Frame中
   - 还拓展了一些其他类型的Frame用于心跳等特性的实现

5. 为什么选用http/2作为传输协议？

   通用性。HTTP作为互联网的基础设施，有负载均衡、正反向代理、安全等成熟的实现和机制，GRPC构建在HTTP/2之上可以直接使用现有设施，无需设计私有协议。

6. GRPC负载均衡存在什么问题？与k8s结合时，需要怎么解决？

   GRPC采用HTTP/2作为底层协议，同一个客户端所有的请求都公用一个连接。即使在建立连接时，每个Server分配的Conn足够均匀。但是如果每个Client的请求数量不同，依旧会导致Grpc Server的负载不均衡。

   在与k8s结合时，k8s仅能保证连接分布的负载均衡，无法保证请求的负载均衡。

   使用headless service，在Grpc Client端用`Dial(dns://)`的方式获取所有的Pod List，然后根据Client端的负载均衡策略，将请求转到不同的Pod上。

## language

### c++

### golang

1. golang有哪些数据类型？

   var、const、type、func

2. 数组和切片有什么区别？

   数组：由相同元素组成的固定大小的集合，支持随机访问

   切片：由相同元素组成的大小不固定的集合。支持随机访问，支持自动扩容。从本质上看，切片是数组某个片段的引用。（pointer、len、cap）

3. 讲讲切片扩容

   当切片的空间不足时，会自动扩容。如果元素数量小于1024，新空间容量直接翻倍；如果元素数量大于1024，新空间容量增长25%。并且后续会将数据从拷贝至新的空间中

4. 有哪些类型可以作为map的key？

   只要Key支持==或者!=判断，就可以作为key

5. 讲讲hashmap的实现

   哈希表。常见两种冲突解决方法：

   - 寻址法：使用一维数组。若出现冲突，将数据放到后续第一个空闲的位置。查询时，如果发现position中的hashKey不匹配，顺序往后查询
   - 拉链法：使用数组+链表（红黑树）。出现冲突时。往链表后面append。

   go在拉链法的基础上，加入了溢出桶机制，目的是为了减少hash扩容的次数。当某个bucket装满时，会将多余的数据装到溢出桶中。一个bucket可以放8个kv

5. 字符串和数组有什么区别？

   字符串是一个只读的字节数组。修改的时候，需要转成[]byte

6. 为什么go的函数调用可以返回多个值？C只能返回1个值？

   go使用栈传递返回参数；c使用寄存器传递返回参数

7. interface是什么？讲讲interface的实现原理

   一个中间层，解耦调用与具体的实现。类似于C++虚函数的实现机制：RTTI + Data + 虚函数表。在运行时，根据类型从函数表中执行具体的函数。

8. 讲讲golang的io多路复用

   golang的io多路复用主要用的是select..case关键字。select可以在多个goroutine中等待多个channel可读可写。当多个channel同时就绪时，会从中随机选出一个执行。

   每个channel中都会存在两个queue：recv & send。当select中没有channel可以读写时，就会将当前goroutine加入到每个case channel queue中，并主动让出处理权。当有goroutine可以读写时，会唤起这个goroutine，并在遍历中获取相应的数据。

9. new和make有什么区别

   make适用于slice、map、channel这样的结构，分配内存并执行初始化；new仅分配内存

10. 讲讲Channel的底层实现.

    mutex + 环形buffer + recv goroutine queue + send goroutine queue

    读：～～

    写：～～

    关闭：唤醒recv queue、send queue上所有的goroutine

11. 讲讲GMP

    G=goroutine，P=processor，M=系统线程。P和M是1对1的关系，P和G是1:n的关系，n最大是256。P会从自己的goroutine队列中取出goroutine进行处理。当队列中的goroutine不足时，会尝试从全局队列中拿，再尝试从其他P的局部队列中拿。

12. 讲讲调度

    Go的调度器是抢占式的。

    协作式抢占（1.14之前）：编译期，在函数调用中插入一些支持抢占的代码。运行期，通过一些触发条件发现需要被抢占了，那就会对这个goroutine进行标记。然后在下一次进入函数调用时，通过预先插入的代码保存goroutine ctx，并且切换为挂起状态，由P重新选择一个goroutine执行

    基于信号的抢占（1.14之后）：编译期没有操作。启动之后，会注册一个SIGURG handler。当发现goroutine需要被抢占时，会向M发送一个信号，然后在single handler中保存goroutine ctx，并切换为挂起状态。之后修改SP寄存器，让执行流转到P中，并重新选一个goroutine执行

13. 触发调度的条件有哪些

    主动挂起；阻塞型系统调用；监控系统；垃圾回收

15. 讲讲三色标记算法

    一共有3种颜色：白色（待回收的垃圾）、灰色（有引用的对象，存在外部引用）、黑色（有引用的对象，并且不存在外部引用）

    初始状态：所有的对象都是白色。然后将全局变量和所有Goroutine栈上的对象全部置灰，然后进入扫描阶段。

    扫描过程：将所有已经扫描的对象修改为黑色，并且将这些对象的引用置灰，并加入扫描队列。直到队列中没有灰色对象为止

    清理过程：清理所有的白色对象。

    上述这个过程存在一个问题：在GC阶段，整个程序是停止的。官方术语叫STW。如果需要并发的执行扫描过程，那就需要处理在扫描过程中新加入的对象。Go用写屏障解决了这样的问题：

    - 插入写屏障：将新加入的对象置灰，保证新加入的对象不会被错误的GC
    - 删除写屏障：将删除对象的置灰，保证删除的对象的引用们会被正确的着色
    - 混合写屏障：在插入时，将对象置黑，去掉了二次扫描的开销；删除时，将对象置灰，保证删除对象的引用们会被正确着色

    用这种方法，就能保证不会出现STW，并且GC过程中新加入对象或者删除老对象不会被错误的GC。

16. 什么时候会触发GC？

    手动触发；系统监控可能触发GC；当内存增长超过一定比例时（内存是上次GC的2倍）

17. 讲讲sync.Mutex的底层实现

    加锁：先自旋一段时间，如果还是不能获取锁，就将当前goroutine加入到mutex的等待列表上，主动让出cpu；自旋是为了避免上下文切换。

    解锁：正常情况下，会根据FIFO的顺序唤醒等待的goroutine；但是如果mutex检测到有goroutine再队列中等待超过1ms，那就切换为饥饿模式，先将锁交给等待时间最长的goroutine；如果检测到有goroutine在队列中等待小于1ms，并且获得了锁。那就再切换回正常模式；

    golang的锁是不可重入锁

18. 讲讲sync.RWMutex的底层实现

    基于mutex，加了一些用于记录读、写goroutine的原子量。当读锁>0时，写锁需要等待；当写锁>0时，读锁需要等待

19. 讲讲sync.Map的底层实现

    主要是使用读写分离的方式提升性能。读的时候先不加锁的读read，不存在再加锁的读dirty；写的时候，直接加锁写dirty；

20. 讲讲sync.WaitGroup底层实现

    用于控制goroutine的并发。Add、Done、Wait。类似于线程屏障（pthread barrier）

21. 讲讲golang计时器的实现原理

    使用最小堆实现的。每个P上一个最小堆，每个P管理自己的定时任务，无须加锁与切换。

22. 讲讲Context包的使用场景

    context主要用于在多个goroutine同步信息。当Cannel类型的Parent Context终止时，所有相关联的Son Context也会终止。有以下几种常用的Context：WithValue、WithCancel、WithTimeout、WithDeadline

23. 讲讲defer的实现原理

    goroutine中有一个defer func list，具有后进先出的特性。只有在函数退出时，才会将执行当前函数关联的defer func

24. 讲讲panic、recover

    类似于c++的异常捕捉机制。只有在同一个goroutine中的panic、recover才能起作用

25. go的锁有哪几种，各自的适用场景是什么？

    互斥锁；读写锁。在并发下，保护状态的一致性

26. 什么是逃逸分析

    编译期间，分析对象应该分配到堆上还是应该分配到栈上。以下几种情况，会将栈上的对象主动分配到堆上：

    - 返回函数中的指针；
    - 往channel中写指针
    - 在切片中写指针
    - 切片太大，导致栈空间不足

    如果发现局部变量的作用域超出该函数，则不会将内存分配在栈上，而是分配在堆上

27. 讲讲go的内存管理

    - 堆内存：
      - 有一个全局的堆管理器，管理大块堆内存。
      - 每个P都一个自己的堆内存管理器，这样在分配时，就无须锁的竞争。P在分配内存时，如果<32KB，会自己分配；如果>32KB，会从全局的堆管理器中进行分配。
      - 所有的P还会共享一个全局的内存列表，当自己的分配完时，就会从这个全局的堆内存列表中分配

      总而言之，Go的堆内存分配是一个层级结构，从下往上依次是：系统堆 -> 公用cache -> 线程cache

    - 栈内存

      Goroutine栈的默认大小是2KB，不足时会自动扩容。扩容大小翻倍；垃圾回收时，如果检测到栈仅用了1/4，大小缩倍。使用的是连续栈，扩容翻倍之后，会进行Copy，并重新设置栈指针

      系统栈默认大小是8MB，不足时会crash。

28. go有哪些常用的并发控制模型？

    context、wg、channel

29. 为什么小对象多了，会造成GC压力？

    GC的扫描速度和对象数量相关，与对象大小无关

30. 怎么在编译期解决data race？

    `go build -race mytest`

31. go什么情况下会发生内存泄漏？

    被全局对象引用，无法释放；goroutine泄漏，导致goroutine管理的内存泄漏

32. 两个nil可能不相等嘛？

    有可能的。在比较时，会从type和value两个角度进行比较。

33. struct能不能比较？

    同类型且field都能比较时，是可以比较的；不同类型不能比较

34. nil切片和空切片有什么区别？

    nil切片没有初始化指向空地址；空切片已经初始化，不过指向的数组为空

35. `for`循环`select`时，如果通道已经关闭会怎么样？如果`select`中的`case`只有一个，又会怎么样？

    - for循环`select`时，如果其中一个case通道已经关闭，则每次都会执行到这个case。
    - 如果select里边只有一个case，而这个case被关闭了，则会出现死循环。

    所以，最好在select中加入default。可以有效防止阻塞

## design

- 设计一个短连接生成系统
- 设计一个rpc
- 大文件排序