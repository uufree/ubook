# Redis实战篇

[TOC]

## 最佳运维实践

### Linux系统

- `vm.overcommit_memory`：建议配置为1，为Fork留足空间

  - 0：内核不允许使用超量内存。
  - 1：内核允许使用超量内存。

  ```bash
  echo "vm.overcommit_memory=1" >> /etc/sysctl.conf
  sysctl vm.overcommit_memory=1
  ```

- `swappiness`：swap空间

  ![image-20211017181816705](assets/image-20211017181816705.png)

  ```bash
  echo vm.swappiness={bestvalue} >> /etc/sysctl.conf
  ```

- `THP`：大内存页（2MB），默认开启。为了防止Fork过慢，建议关闭。

  ```bash
  echo never > /sys/kernel/mm/transparent_hugepage/enabled
  ```

- `NTP`：宿主机时间同步配置

  ```bash
  0 * * * * /usr/sbin/ntpdate ntp.xx.com > /dev/null 2>&1
  ```

- 增加进程的文件描述符数量

  ```bash
  ulimit –Sn {max-open-files}
  ```

- `TCP backlog`

  ```bash
  echo 511 > /proc/sys/net/core/somaxconn
  ```

### 慢查询日志

- 配置项：
  - `slowlog-log-slower-than`：慢查询阈值，默认10000us = 10ms。
  - `slowlog-max-len`：慢查询日志队列长度，默认128
  
- 操作命令：

  - 获取慢查询日志：`slowlog get [n]`
  - 获取慢查询日志队列长度：`slowlog len`
  - 慢查询日志重置：`slowlog reset`

- 慢查询日志消息格式：

  ![image-20210930110925907](assets/image-20210930110925907.png)

- 注意事项：

  - 慢查询**仅记录命令执行时间**，并不包括排队和网络传输的时间
  - 慢查询是一个先进先出的队列，如果慢查询比较多的情况下，可能会导致慢查询日志丢失。为了防止这种情况发生，可以定期执行`slowlog get`命令将慢查询日志持久化到其他存储中。

### AOF与RDB持久化

- **fork操作**

  fork操作涉及到页表拷贝，比较耗时。改善方式如下：

  - 限制单个实例的内存。建议控制在10GB以内（对应页表大小约为20MB）
  - 降低fork操作的频率。包括放宽aof-rewrite的限制、降低bgsave的频率。

- **子进程开销监控和优化**

  子进程负责AOF和RDB文件的重写，主要涉及到CPU、内存、硬盘的开销、

  - CPU
    - 不要做绑定单核CPU操作，由于子进程非常消耗CPU，会和父进程产生单核资源竞争
    - 不要和其他CPU密集型服务部署在一起，防止CPU过度竞争
  - 内存：页表拷贝和写时复制会消耗一定的内存
  - 硬盘
    - 防止和消息队列、存储等高硬盘负载的服务部署在一起
    - AOF重写时会消耗大量的硬盘IO，可以开启配置`no-appendfile-on-rewrite`，表示在AOF期间不做fsync操作
    - 对于单机配置多个Redis实例的情况，可以配置不同实例分盘存储AOF文件，分摊硬盘写入压力

- **AOF追加阻塞**

  使用AOF同步策略为`everysec`时，Redis实例会启用后台线程每秒执行一次fsync同步硬盘。当系统硬盘资源繁忙时，会造成Redis主线程阻塞。优化方式如上所述。

### 副本

- **读写分离**

  - 复制数据延迟：无解，只能要求应用容忍短时间内的数据延迟

  - 从副本读到过期数据

    > 注：已在Redis 3.2版本解决这个问题。从节点会帮助检查数据是否已过期

  - 从节点故障：需要客户端维护可用的副本列表，轮询访问数据

  - 总结：**单纯的使用副本机制做读写分离了，非常鸡肋，且麻烦重重。不建议使用。**

- **主从配置不一致**

  如果主从配置不一致，尤其是`maxmemory`、`hash-max-ziplist-entries`等参数，会导致副本丢失数据。切记，部署时应该人工检查。

- **规避复制风暴**

  - 主节点异常重启，从节点观查到RunID不一致，会进行全量复制。建议：**采用树状拓扑**。
  - 当多个主节点部署在同一台物理机上。并且这台物理机出现网络故障。恢复后，会产生复制风暴。建议：**将主节点部署在不同的机器上。**

### 阻塞

- 内在原因

  - **数据结构使用不合理**

    - 使用了高复杂度命令，如：`hgetall`，`keys`等
    - 出现了大对象。使用：`redis-cli -a xxxx -d 0 --bigkeys`检测
    - 数据结构编码方式配置不合理。以`hash`为例，手动调整了内部编码格式切换的界限

  - **CPU饱和**：使用`redis-cli -a xxxx --stat`查看redis-server的请求处理情况，判断是否超过处理能力边界

  - **持久化相关**

    - fork阻塞

    - AOF刷盘阻塞

      > 当硬盘压力过载时，每秒一次的fsync会很慢，造成阻塞

    - 写时复制HugePage(2MB)内存页导致阻塞

- 外在原因

  - **CPU竞争**
    - 进程竞争：部署问题，将Redis与其他CPU密集型服务部署在一起。不过，使用k8s的话，基本不存在
    - 绑定CPU：绑定CPU可用于降低CPU频繁的上下文切换开销。但是，**如果开启了AOF持久化或参与复制（RDB），将导致子进程和父进程共享CPU，导致出现竞争**
  - **内存交换**：部署问题，开启Swap内存交换

### 哨兵

建议：**在部署分布式Redis时，尽量保证机器时间一致**。

1. **节点下线**

   使用`sentinel failover <master-name>`强制主节点下线

2. **节点上线**

   - 从节点：`--slaveof <master host> <master port>`
   - Sentinel节点：注意配置文件中的`sentinel monitor <master name> <master host> <master port> <quorum>`填写正确

### 集群

建议：**在部署分布式Redis时，尽量保证机器时间一致**。

1. **集群功能特点**
   - 批量操作支持有限。仅支持具有相同Slot的Key执行批量操作
   - 仅能在分布在同一台机器上的Key执行事务操作
   - 不支持多库
   - 复制结构只支持1层
   
2. 集群模式如何支持读写分离？

   **集群模式默认仅支持在主节点上进行读写。**多个主节点已经可以从容的拓展读写能力，无需再使用从节点进行读分压。启用从节点读可能引入：复制延迟、数据过期等问题。

## 最佳使用实践

### 缓存

1. **为什么使用缓存**？

   - 读写加速，提升用户体验

   - 降低后端负载
   
    但是会引两个问题：
   
   - 数据不一致。缓存层与数据层存在数据不一致的可能，与**更新策略**相关
   - 引入缓存组件，提升运维成本

2. **缓存更新策略最佳实践**

![image-20211017180040197](assets/image-20211017180040197.png)

- 低一致性业务：配置最大内存和淘汰策略，需要的话，再加上定时即可
- 高一致性业务：**超时剔除 + 主动更新**

3. 什么是**缓存穿透**？怎么优化？

   缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。即：**底层数据库没有数据且缓存内也没有数据**

   两种解决方式：

   - 缓存空对象

   ![image-20211017180452627](assets/image-20211017180452627.png)

   - 布隆过滤器拦截

     > 如果布隆过滤器认为这个值不存在，那么这个值就一定不存在
     >
     > 如果布控过滤去认为这个值存在，那么这个值就一定存在

   ![image-20211017180721486](assets/image-20211017180721486.png)

4. 什么是**缓存击穿**，怎么优化？

   当热点数据key从缓存内失效时，大量访问同时请求这个数据，就会将查询下沉到数据库层，此时数据库层的负载压力会骤增，我们称这种现象为"缓存击穿"。即：**底层数据库有数据而缓存内没有数据**。解决方式：
   
- 热点Key永不过期
   - 利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的这个数据
   
5. 什么是**缓存雪崩**，怎么优化？

   **缓存雪崩是指Redis中大量的key几乎同时过期**，然后大量并发查询穿过redis击打到底层数据库上，导致数据库层的负载压力会骤增的现象。解决方式：

   - 热点Key永不过期

   - 在Key的过期时间上加随机数
   - **使用互斥锁保证：同时只有一个客户端访问数据层**

![image-20211017181126955](assets/image-20211017181126955.png)

### 分布式锁

> **原子操作**：不会被线程调度机制打断的操作，不会被switch context中断

- 单实例锁

  ```bash
  // acquire lock
  set lock {random-number} ex 5 nx
  ....
  
  // release lock
  if  equal random-number:
  	del lock
  ```

  使用**random number**是因为考虑到这样一种情形：

  1. 线程A持有锁超过了超时时间的限制
  2. 锁过期后线程B获取了这把锁
  3. 线程A的任务结束。如果没有用**random number**去判断，那么线程A会直接删除这把锁，导致线程C直接拿到锁

  但是引入**random number**后，因为redis不支持delifequal这样的命令，所以需要用Lua脚本封装一个**delifequal**的原子操作：

  ```bash
  if redis.call("get",KEYS[1]) == ARGV[1] then
  	return redis.call("del",KEYS[1])
  else
  	return 0
  end
  ```

- RedLock（多实例锁）

  TODO...

- **锁冲突的解决方式**：
  
  1. 抛出异常，由业务代码做**退避重试**

### 限流

**漏斗限流算法**，使用Redis-Cell插件实现。使用方式详见：redis命令篇。

![image-20211018210535205](assets/image-20211018210535205.png)



### 特定业务场景

1. C端，**统计需求**：统计用户签到记录

   可以使用**Bitmap**统计用户365天的登录情况，有效节省用户空间

2. C端，**统计需求**：统计网页页面的PV和UV。

   > PV：每个网页的访问次数，统计总访问量
   >
   > UV：每个网页的独立访问（一个用户访问多次也只能算一次），统计用户量

   - PV：每个网页一个计数机，使用`incrby`累加即可
   - UV：
     - 方案1：每个网页一个Set结构，访问到达之后，直接往Set中加入UserID即可
     - 方案2：使用**HyperLogLog**对网页访问量进行计数。此种计数方式存在误差，大约0.81%。但非常非常节省空间
   
3. C/B端，**去重需求**：图片MD5去重、防止大量伪造的RequestID打穿Mysql

   - 方案1：使用Set过滤重复的请求。精确，但是占用空间过大
   - 方案2：使用**Bloom Filter**过滤重复的请求。有误差，但是占用空间小。



